{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM WITHOUT TA,FEATURE REDUCTION AND ADABOOST</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8531746031746031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       152\n",
      "           1       0.92      0.69      0.79       100\n",
      "\n",
      "    accuracy                           0.85       252\n",
      "   macro avg       0.87      0.83      0.84       252\n",
      "weighted avg       0.86      0.85      0.85       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.1).mean()\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "svm = SVC(C=9.699920698680053,class_weight='balanced',degree=5,coef0=6.080765165859437 ,kernel='linear', gamma=0.02997773203425469, probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CV FOR SVM WITHOUT TA AND ADABOOST</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        16\n",
      "           1       1.00      0.21      0.35        98\n",
      "\n",
      "    accuracy                           0.32       114\n",
      "   macro avg       0.59      0.61      0.32       114\n",
      "weighted avg       0.88      0.32      0.34       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.27        16\n",
      "           1       1.00      0.10      0.19        98\n",
      "\n",
      "    accuracy                           0.23       114\n",
      "   macro avg       0.58      0.55      0.23       114\n",
      "weighted avg       0.88      0.23      0.20       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.65        36\n",
      "           1       0.89      0.65      0.76        78\n",
      "\n",
      "    accuracy                           0.71       114\n",
      "   macro avg       0.71      0.74      0.70       114\n",
      "weighted avg       0.78      0.71      0.72       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63        46\n",
      "           1       1.00      0.22      0.36        68\n",
      "\n",
      "    accuracy                           0.54       114\n",
      "   macro avg       0.73      0.61      0.50       114\n",
      "weighted avg       0.78      0.54      0.47       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90        99\n",
      "           1       0.42      0.67      0.51        15\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.68      0.76      0.71       114\n",
      "weighted avg       0.88      0.83      0.85       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58        48\n",
      "           1       0.69      0.62      0.66        66\n",
      "\n",
      "    accuracy                           0.62       114\n",
      "   macro avg       0.62      0.62      0.62       114\n",
      "weighted avg       0.63      0.62      0.63       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.58      0.67        71\n",
      "           1       0.52      0.77      0.62        43\n",
      "\n",
      "    accuracy                           0.65       114\n",
      "   macro avg       0.66      0.67      0.65       114\n",
      "weighted avg       0.70      0.65      0.65       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        46\n",
      "           1       0.90      0.84      0.87        68\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.84      0.85      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88        72\n",
      "           1       0.80      0.76      0.78        42\n",
      "\n",
      "    accuracy                           0.84       114\n",
      "   macro avg       0.83      0.83      0.83       114\n",
      "weighted avg       0.84      0.84      0.84       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        80\n",
      "           1       1.00      0.59      0.74        34\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.93      0.79      0.83       114\n",
      "weighted avg       0.90      0.88      0.87       114\n",
      "\n",
      "Average Accuracy across folds: 0.6473684210526316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(C=9.699920698680053, kernel='linear', degree=5, coef0=6.080765165859437, gamma=0.02997773203425469, class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>SVM WITH TA AND FEATURE REDUCTION</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       152\n",
      "           1       0.96      0.76      0.85        95\n",
      "\n",
      "    accuracy                           0.89       247\n",
      "   macro avg       0.91      0.87      0.88       247\n",
      "weighted avg       0.90      0.89      0.89       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ta  # Import the technical analysis library\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "# Assuming ea_df is your DataFrame loaded with stock data including 'Open', 'High', 'Low', 'Close', 'Volume'\n",
    "\n",
    "# Calculate Moving Average\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=20).mean()\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()  \n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.2).mean()\n",
    "\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "ea_df.dropna(inplace=True)\n",
    "# Update features list to include the new technical indicators\n",
    "features = ['Close', 'SMA_10', 'MACD', 'ADX','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm = SVC(C=0.7400230211761833, kernel='rbf',degree=4,coef0=0.09111040120352687, gamma=0.2002723939261901, class_weight='balanced', probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      1.00      0.34        16\n",
      "           1       1.00      0.35      0.52        96\n",
      "\n",
      "    accuracy                           0.45       112\n",
      "   macro avg       0.60      0.68      0.43       112\n",
      "weighted avg       0.89      0.45      0.50       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.67      0.81      0.73        80\n",
      "\n",
      "    accuracy                           0.58       112\n",
      "   macro avg       0.34      0.41      0.37       112\n",
      "weighted avg       0.48      0.58      0.52       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66        22\n",
      "           1       1.00      0.74      0.85        90\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.74      0.87      0.76       112\n",
      "weighted avg       0.90      0.79      0.81       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.78        56\n",
      "           1       0.89      0.55      0.68        56\n",
      "\n",
      "    accuracy                           0.74       112\n",
      "   macro avg       0.78      0.74      0.73       112\n",
      "weighted avg       0.78      0.74      0.73       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        89\n",
      "           1       0.63      0.83      0.72        23\n",
      "\n",
      "    accuracy                           0.87       112\n",
      "   macro avg       0.79      0.85      0.81       112\n",
      "weighted avg       0.89      0.87      0.87       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.15      0.23        46\n",
      "           1       0.59      0.86      0.70        66\n",
      "\n",
      "    accuracy                           0.57       112\n",
      "   macro avg       0.52      0.51      0.46       112\n",
      "weighted avg       0.53      0.57      0.51       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40        77\n",
      "           1       0.38      1.00      0.55        35\n",
      "\n",
      "    accuracy                           0.48       112\n",
      "   macro avg       0.69      0.62      0.47       112\n",
      "weighted avg       0.81      0.48      0.44       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        41\n",
      "           1       0.97      0.93      0.95        71\n",
      "\n",
      "    accuracy                           0.94       112\n",
      "   macro avg       0.93      0.94      0.93       112\n",
      "weighted avg       0.94      0.94      0.94       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        71\n",
      "           1       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.91       112\n",
      "   macro avg       0.92      0.89      0.90       112\n",
      "weighted avg       0.91      0.91      0.91       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        80\n",
      "           1       1.00      0.44      0.61        32\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.91      0.72      0.75       112\n",
      "weighted avg       0.87      0.84      0.82       112\n",
      "\n",
      "Average Accuracy across folds: 0.7169642857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(C=0.7400230211761833, kernel='rbf', degree=4, coef0=0.09111040120352687, gamma=0.2002723939261901, class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>svm with ta and ada boost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8866396761133604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       152\n",
      "           1       0.99      0.72      0.83        95\n",
      "\n",
      "    accuracy                           0.89       247\n",
      "   macro avg       0.92      0.85      0.87       247\n",
      "weighted avg       0.90      0.89      0.88       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ta  # Import the technical analysis library\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "# Assuming ea_df is your DataFrame loaded with stock data including 'Open', 'High', 'Low', 'Close', 'Volume'\n",
    "\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=10).mean()\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.2).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = [ 'High', 'Low', 'Close', 'Volume', 'SMA_10', 'MACD', 'ADX','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm = SVC(C=0.7400230211761833, kernel='rbf',degree=4,coef0=0.09111040120352687, gamma=0.2002723939261901, class_weight='balanced', probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8906882591093117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       152\n",
      "           1       1.00      0.72      0.83        95\n",
      "\n",
      "    accuracy                           0.89       247\n",
      "   macro avg       0.92      0.86      0.88       247\n",
      "weighted avg       0.91      0.89      0.89       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize the SVM model with probability=True for AdaBoost compatibility\n",
    "svm_base = SVC(C=8, kernel='rbf', gamma=0.01, class_weight=None, probability=True, random_state=42)\n",
    "\n",
    "# Initialize and train the AdaBoost model with SVM as the base estimator\n",
    "ada_boost_model = AdaBoostClassifier(base_estimator=svm_base, n_estimators=50, random_state=42)\n",
    "ada_boost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the AdaBoost model\n",
    "y_pred = ada_boost_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CV FOR SVM WITH TA AND ADABOOST</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.86      1.00      0.92        96\n",
      "\n",
      "    accuracy                           0.86       112\n",
      "   macro avg       0.43      0.50      0.46       112\n",
      "weighted avg       0.73      0.86      0.79       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.71      1.00      0.83        80\n",
      "\n",
      "    accuracy                           0.71       112\n",
      "   macro avg       0.36      0.50      0.42       112\n",
      "weighted avg       0.51      0.71      0.60       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.80      1.00      0.89        90\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.40      0.50      0.45       112\n",
      "weighted avg       0.65      0.80      0.72       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        56\n",
      "           1       0.50      1.00      0.67        56\n",
      "\n",
      "    accuracy                           0.50       112\n",
      "   macro avg       0.25      0.50      0.33       112\n",
      "weighted avg       0.25      0.50      0.33       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        89\n",
      "           1       0.21      1.00      0.34        23\n",
      "\n",
      "    accuracy                           0.21       112\n",
      "   macro avg       0.10      0.50      0.17       112\n",
      "weighted avg       0.04      0.21      0.07       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.33      0.43        46\n",
      "           1       0.65      0.86      0.74        66\n",
      "\n",
      "    accuracy                           0.64       112\n",
      "   macro avg       0.64      0.59      0.58       112\n",
      "weighted avg       0.64      0.64      0.61       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        77\n",
      "           1       0.31      1.00      0.48        35\n",
      "\n",
      "    accuracy                           0.31       112\n",
      "   macro avg       0.16      0.50      0.24       112\n",
      "weighted avg       0.10      0.31      0.15       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85        41\n",
      "           1       0.88      0.97      0.93        71\n",
      "\n",
      "    accuracy                           0.90       112\n",
      "   macro avg       0.91      0.88      0.89       112\n",
      "weighted avg       0.91      0.90      0.90       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        71\n",
      "           1       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.88       112\n",
      "   macro avg       0.90      0.85      0.87       112\n",
      "weighted avg       0.89      0.88      0.88       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        80\n",
      "           1       1.00      0.47      0.64        32\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.91      0.73      0.77       112\n",
      "weighted avg       0.87      0.85      0.83       112\n",
      "\n",
      "Average Accuracy across folds: 0.6669642857142857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Load your data and preprocess as you have specified\n",
    "# Code for data loading and preprocessing is assumed to be done here\n",
    "\n",
    "# Define the time series cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model with probability=True for AdaBoost compatibility\n",
    "svm_base = SVC(C=8, kernel='rbf', gamma=0.01, class_weight=None, probability=True, random_state=42)\n",
    "\n",
    "# Initialize the AdaBoost model with SVM as the base estimator\n",
    "ada_boost_model = AdaBoostClassifier(base_estimator=svm_base, n_estimators=50, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the AdaBoost model\n",
    "    ada_boost_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = ada_boost_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
