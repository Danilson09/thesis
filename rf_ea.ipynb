{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import ta\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2019-03-01  96.830002  97.940002  95.309998  97.410004  95.533249  4443600\n",
      "1  2019-03-04  98.309998  99.430000  95.570000  97.290001  95.415581  7187200\n",
      "2  2019-03-05  96.260002  97.059998  95.150002  95.720001  93.875832  6041900\n",
      "3  2019-03-06  95.320000  96.379997  94.129997  94.769997  92.944115  3987500\n",
      "4  2019-03-07  95.000000  99.559998  94.470001  99.360001  97.445694  8866800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "print(ea_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF MODEL WITHout TA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8492063492063492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       152\n",
      "           1       0.78      0.87      0.82       100\n",
      "\n",
      "    accuracy                           0.85       252\n",
      "   macro avg       0.84      0.85      0.85       252\n",
      "weighted avg       0.86      0.85      0.85       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ea_df = pd.read_csv(file_path)\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "features = ['Open',  'Low', 'Close', 'Volume','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "\n",
    "# Assuming 'Target' is your target variable\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42,shuffle=False)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=243, random_state=42,max_depth= 5)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.26        16\n",
      "           1       1.00      0.07      0.14        96\n",
      "\n",
      "    accuracy                           0.21       112\n",
      "   macro avg       0.58      0.54      0.20       112\n",
      "weighted avg       0.88      0.21      0.15       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.66      0.79      0.72        80\n",
      "\n",
      "    accuracy                           0.56       112\n",
      "   macro avg       0.33      0.39      0.36       112\n",
      "weighted avg       0.47      0.56      0.51       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.44        22\n",
      "           1       1.00      0.39      0.56        90\n",
      "\n",
      "    accuracy                           0.51       112\n",
      "   macro avg       0.64      0.69      0.50       112\n",
      "weighted avg       0.86      0.51      0.54       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79        56\n",
      "           1       0.82      0.71      0.76        56\n",
      "\n",
      "    accuracy                           0.78       112\n",
      "   macro avg       0.78      0.78      0.78       112\n",
      "weighted avg       0.78      0.78      0.78       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74        89\n",
      "           1       0.36      0.83      0.50        23\n",
      "\n",
      "    accuracy                           0.66       112\n",
      "   macro avg       0.65      0.72      0.62       112\n",
      "weighted avg       0.81      0.66      0.69       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        46\n",
      "           1       0.59      1.00      0.74        66\n",
      "\n",
      "    accuracy                           0.59       112\n",
      "   macro avg       0.29      0.50      0.37       112\n",
      "weighted avg       0.35      0.59      0.44       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.34      0.48        77\n",
      "           1       0.36      0.83      0.50        35\n",
      "\n",
      "    accuracy                           0.49       112\n",
      "   macro avg       0.59      0.58      0.49       112\n",
      "weighted avg       0.67      0.49      0.49       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74        41\n",
      "           1       0.81      0.97      0.88        71\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.87      0.79      0.81       112\n",
      "weighted avg       0.85      0.84      0.83       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88        71\n",
      "           1       0.76      0.85      0.80        41\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.83      0.85      0.84       112\n",
      "weighted avg       0.85      0.85      0.85       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        80\n",
      "           1       1.00      0.62      0.77        32\n",
      "\n",
      "    accuracy                           0.89       112\n",
      "   macro avg       0.93      0.81      0.85       112\n",
      "weighted avg       0.91      0.89      0.88       112\n",
      "\n",
      "Average Accuracy across folds: 0.6375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model\n",
    "rf = RandomForestClassifier(n_estimators=243, random_state=42,max_depth= 20)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF MODEL WITH TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8825910931174089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       152\n",
      "           1       0.88      0.80      0.84        95\n",
      "\n",
      "    accuracy                           0.88       247\n",
      "   macro avg       0.88      0.87      0.87       247\n",
      "weighted avg       0.88      0.88      0.88       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'EA_stock_data.csv'\n",
    "# Assuming ea_df is your DataFrame loaded with stock data including 'Open', 'High', 'Low', 'Close', 'Volume'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "# Calculate Moving Average\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=20).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = ['Open', 'Low', 'Close', 'Volume','SMA_10', 'MACD','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "\n",
    "y = ea_df['Target'].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=476, random_state=42,max_depth= 20) \n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv for rf model with ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.26        16\n",
      "           1       1.00      0.07      0.14        96\n",
      "\n",
      "    accuracy                           0.21       112\n",
      "   macro avg       0.58      0.54      0.20       112\n",
      "weighted avg       0.88      0.21      0.15       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.66      0.79      0.72        80\n",
      "\n",
      "    accuracy                           0.56       112\n",
      "   macro avg       0.33      0.39      0.36       112\n",
      "weighted avg       0.47      0.56      0.51       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.44        22\n",
      "           1       1.00      0.39      0.56        90\n",
      "\n",
      "    accuracy                           0.51       112\n",
      "   macro avg       0.64      0.69      0.50       112\n",
      "weighted avg       0.86      0.51      0.54       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78        56\n",
      "           1       0.81      0.70      0.75        56\n",
      "\n",
      "    accuracy                           0.77       112\n",
      "   macro avg       0.77      0.77      0.77       112\n",
      "weighted avg       0.77      0.77      0.77       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.63      0.75        89\n",
      "           1       0.37      0.83      0.51        23\n",
      "\n",
      "    accuracy                           0.67       112\n",
      "   macro avg       0.65      0.73      0.63       112\n",
      "weighted avg       0.82      0.67      0.70       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        46\n",
      "           1       0.59      1.00      0.74        66\n",
      "\n",
      "    accuracy                           0.59       112\n",
      "   macro avg       0.29      0.50      0.37       112\n",
      "weighted avg       0.35      0.59      0.44       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.34      0.48        77\n",
      "           1       0.37      0.86      0.52        35\n",
      "\n",
      "    accuracy                           0.50       112\n",
      "   macro avg       0.60      0.60      0.50       112\n",
      "weighted avg       0.69      0.50      0.49       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74        41\n",
      "           1       0.81      0.97      0.88        71\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.87      0.79      0.81       112\n",
      "weighted avg       0.85      0.84      0.83       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88        71\n",
      "           1       0.76      0.85      0.80        41\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.83      0.85      0.84       112\n",
      "weighted avg       0.85      0.85      0.85       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        80\n",
      "           1       1.00      0.66      0.79        32\n",
      "\n",
      "    accuracy                           0.90       112\n",
      "   macro avg       0.94      0.83      0.86       112\n",
      "weighted avg       0.91      0.90      0.89       112\n",
      "\n",
      "Average Accuracy across folds: 0.6392857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model\n",
    "rf = RandomForestClassifier(n_estimators=476, random_state=42,max_depth= 20)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf with ta and ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8906882591093117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       152\n",
      "           1       0.90      0.81      0.85        95\n",
      "\n",
      "    accuracy                           0.89       247\n",
      "   macro avg       0.89      0.88      0.88       247\n",
      "weighted avg       0.89      0.89      0.89       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'EA_stock_data.csv'\n",
    "import ta  # Import the technical analysis library\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate Moving Average\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=20).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = ['Open', 'Low', 'Close', 'Volume','SMA_10', 'MACD','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "y = ea_df['Target'].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize and train the AdaBoost model with RandomForest as the base estimator\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "base_rf_classifier = RandomForestClassifier(n_estimators=476, random_state=42,max_depth= 20)  # Base estimator\n",
    "ada_boost_classifier = AdaBoostClassifier(\n",
    "    base_estimator=base_rf_classifier,random_state=42,n_estimators=92, learning_rate=0.4232124682782118\n",
    "    \n",
    ")\n",
    "ada_boost_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "predictions = ada_boost_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions, zero_division=0))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.94      0.28        16\n",
      "           1       0.95      0.20      0.33        96\n",
      "\n",
      "    accuracy                           0.30       112\n",
      "   macro avg       0.56      0.57      0.30       112\n",
      "weighted avg       0.84      0.30      0.32       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.68      0.85      0.76        80\n",
      "\n",
      "    accuracy                           0.61       112\n",
      "   macro avg       0.34      0.42      0.38       112\n",
      "weighted avg       0.49      0.61      0.54       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      1.00      0.46        22\n",
      "           1       1.00      0.43      0.60        90\n",
      "\n",
      "    accuracy                           0.54       112\n",
      "   macro avg       0.65      0.72      0.53       112\n",
      "weighted avg       0.86      0.54      0.58       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80        56\n",
      "           1       0.84      0.68      0.75        56\n",
      "\n",
      "    accuracy                           0.78       112\n",
      "   macro avg       0.79      0.78      0.77       112\n",
      "weighted avg       0.79      0.78      0.77       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73        89\n",
      "           1       0.35      0.83      0.49        23\n",
      "\n",
      "    accuracy                           0.64       112\n",
      "   macro avg       0.64      0.71      0.61       112\n",
      "weighted avg       0.81      0.64      0.68       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.04      0.08        46\n",
      "           1       0.58      0.94      0.72        66\n",
      "\n",
      "    accuracy                           0.57       112\n",
      "   macro avg       0.46      0.49      0.40       112\n",
      "weighted avg       0.48      0.57      0.46       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.29      0.43        77\n",
      "           1       0.36      0.89      0.51        35\n",
      "\n",
      "    accuracy                           0.47       112\n",
      "   macro avg       0.60      0.59      0.47       112\n",
      "weighted avg       0.69      0.47      0.45       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65        41\n",
      "           1       0.78      0.90      0.84        71\n",
      "\n",
      "    accuracy                           0.78       112\n",
      "   macro avg       0.77      0.73      0.74       112\n",
      "weighted avg       0.78      0.78      0.77       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88        71\n",
      "           1       0.78      0.85      0.81        41\n",
      "\n",
      "    accuracy                           0.86       112\n",
      "   macro avg       0.84      0.86      0.85       112\n",
      "weighted avg       0.86      0.86      0.86       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        80\n",
      "           1       0.95      0.62      0.75        32\n",
      "\n",
      "    accuracy                           0.88       112\n",
      "   macro avg       0.91      0.81      0.84       112\n",
      "weighted avg       0.89      0.88      0.88       112\n",
      "\n",
      "Average Accuracy across folds: 0.6437499999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta  # Make sure you have the TA-Lib installed\n",
    "\n",
    "# Load your data\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "# Your preprocessing code comes here\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = ['Open', 'Low', 'Close', 'Volume', 'SMA_10', 'MACD', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Define the target variable and standardize the features\n",
    "y = ea_df['Target'].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the time series cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the RandomForest classifier as the base estimator\n",
    "base_rf_classifier = RandomForestClassifier(n_estimators=476, random_state=42, max_depth=20)\n",
    "\n",
    "# Initialize the AdaBoost model with RandomForest as the base estimator\n",
    "ada_boost_classifier = AdaBoostClassifier(base_estimator=base_rf_classifier, n_estimators=92, learning_rate=0.4232124682782118, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the AdaBoost model\n",
    "    ada_boost_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = ada_boost_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters for rf without anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:45<00:00,  2.26s/trial, best loss: -0.7359533919225832]\n",
      "Best parameters: {'max_depth': 5.0, 'n_estimators': 243.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, TimeSeriesSplit\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "import numpy as np\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = ['Open',  'Low', 'Close', 'Volume','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "\n",
    "y = ea_df['Target'].cat.codes  # Convert categorical data to integer codes\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 500, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)),  # Corrected this line\n",
    "    # Other parameters can be added here as needed\n",
    "}\n",
    "\n",
    "# Example Objective function (ensure you define X_scaled, y, and include necessary imports)\n",
    "def objective(params):\n",
    "    clf = RandomForestClassifier(**params, random_state=42)\n",
    "    # Placeholder for cross_val_score, replace X_scaled and y with your data and target variables\n",
    "    score = cross_val_score(clf, X_scaled, y, scoring='accuracy').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# Example of running the optimization (make sure to define or import your data)\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters:\", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyper parameters for rf with ta and no adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:36<00:00,  3.37s/trial, best loss: -0.7084230275501134]\n",
      "Best parameters: {'max_depth': 5.0, 'n_estimators': 476.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, TimeSeriesSplit\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "import numpy as np\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = ['Open', 'Low', 'Close', 'Volume','SMA_10', 'MACD','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "\n",
    "y = ea_df['Target'].cat.codes  # Convert categorical data to integer codes\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 500, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)),  # Corrected this line\n",
    "    # Other parameters can be added here as needed\n",
    "}\n",
    "\n",
    "# Example Objective function (ensure you define X_scaled, y, and include necessary imports)\n",
    "def objective(params):\n",
    "    clf = RandomForestClassifier(**params, random_state=42)\n",
    "    # Placeholder for cross_val_score, replace X_scaled and y with your data and target variables\n",
    "    score = cross_val_score(clf, X_scaled, y, scoring='accuracy').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# Example of running the optimization (make sure to define or import your data)\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameters for ta and ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:55:00<00:00, 34.50s/trial, best loss: -0.6857410881801125]   \n",
      "Best parameters: {'learning_rate': 0.011098446043865652, 'max_depth': 6.0, 'n_estimators': 323.0, 'n_estimators_ab': 50.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Ensure you have imported necessary modules and defined your dataset (X_scaled and y)\n",
    "\n",
    "\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = ['Open', 'Low', 'Close', 'Volume','SMA_10', 'MACD','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "\n",
    "y = ea_df['Target'].cat.codes  # Convert categorical data to integer codes\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 500, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)),\n",
    "    'n_estimators_ab': scope.int(hp.quniform('n_estimators_ab', 50, 200, 1)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 1.0,2),\n",
    "    # If you decide to include the algorithm parameter:\n",
    "    # 'algorithm': hp.choice('algorithm', ['SAMME', 'SAMME.R']),\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    # Create the base estimator with corrected parameters\n",
    "    rf_base = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'],  # Corrected to match key in `space`\n",
    "        max_depth=params['max_depth'],        # Corrected to match key in `space`\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create the AdaBoost model with the RandomForest base estimator\n",
    "    clf = AdaBoostClassifier(\n",
    "        base_estimator=rf_base,\n",
    "        n_estimators=params['n_estimators_ab'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        random_state=42\n",
    "        # If including 'algorithm', ensure you map the index to the actual string value:\n",
    "        # algorithm=['SAMME', 'SAMME.R'][params['algorithm']],\n",
    "    )\n",
    "    \n",
    "    # Use a consistent cross-validation method\n",
    "    score = cross_val_score(clf, X_scaled, y, scoring='accuracy').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=200,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.30701754385964913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        16\n",
      "           1       1.00      0.19      0.32        98\n",
      "\n",
      "    accuracy                           0.31       114\n",
      "   macro avg       0.58      0.60      0.31       114\n",
      "weighted avg       0.88      0.31      0.32       114\n",
      "\n",
      "Fold Accuracy: 0.7719298245614035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.85      0.90      0.87        98\n",
      "\n",
      "    accuracy                           0.77       114\n",
      "   macro avg       0.42      0.45      0.44       114\n",
      "weighted avg       0.73      0.77      0.75       114\n",
      "\n",
      "Fold Accuracy: 0.7280701754385965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        36\n",
      "           1       1.00      0.60      0.75        78\n",
      "\n",
      "    accuracy                           0.73       114\n",
      "   macro avg       0.77      0.80      0.73       114\n",
      "weighted avg       0.85      0.73      0.74       114\n",
      "\n",
      "Fold Accuracy: 0.6403508771929824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.96      0.68        46\n",
      "           1       0.94      0.43      0.59        68\n",
      "\n",
      "    accuracy                           0.64       114\n",
      "   macro avg       0.73      0.69      0.63       114\n",
      "weighted avg       0.77      0.64      0.62       114\n",
      "\n",
      "Fold Accuracy: 0.6754385964912281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.68      0.78        99\n",
      "           1       0.24      0.67      0.35        15\n",
      "\n",
      "    accuracy                           0.68       114\n",
      "   macro avg       0.58      0.67      0.57       114\n",
      "weighted avg       0.84      0.68      0.73       114\n",
      "\n",
      "Fold Accuracy: 0.5526315789473685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.06      0.11        48\n",
      "           1       0.57      0.91      0.70        66\n",
      "\n",
      "    accuracy                           0.55       114\n",
      "   macro avg       0.45      0.49      0.40       114\n",
      "weighted avg       0.47      0.55      0.45       114\n",
      "\n",
      "Fold Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33        71\n",
      "           1       0.43      1.00      0.60        43\n",
      "\n",
      "    accuracy                           0.50       114\n",
      "   macro avg       0.71      0.60      0.47       114\n",
      "weighted avg       0.78      0.50      0.43       114\n",
      "\n",
      "Fold Accuracy: 0.6578947368421053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.15      0.26        46\n",
      "           1       0.64      1.00      0.78        68\n",
      "\n",
      "    accuracy                           0.66       114\n",
      "   macro avg       0.82      0.58      0.52       114\n",
      "weighted avg       0.78      0.66      0.57       114\n",
      "\n",
      "Fold Accuracy: 0.7719298245614035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79        72\n",
      "           1       0.63      0.90      0.75        42\n",
      "\n",
      "    accuracy                           0.77       114\n",
      "   macro avg       0.78      0.80      0.77       114\n",
      "weighted avg       0.82      0.77      0.78       114\n",
      "\n",
      "Fold Accuracy: 0.8859649122807017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        80\n",
      "           1       0.96      0.65      0.77        34\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.91      0.82      0.85       114\n",
      "weighted avg       0.89      0.89      0.88       114\n",
      "\n",
      "Average Accuracy across all folds: 0.6491228070175439\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the data\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the data\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['Open', 'Low', 'Close', 'Volume', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Set up the TimeSeriesSplit cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=243, max_depth=5, random_state=42)\n",
    "\n",
    "# List to store scores and create a loop to perform cross-validation\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(\"Fold Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(\"Average Accuracy across all folds:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.20535714285714285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.26        16\n",
      "           1       1.00      0.07      0.14        96\n",
      "\n",
      "    accuracy                           0.21       112\n",
      "   macro avg       0.58      0.54      0.20       112\n",
      "weighted avg       0.88      0.21      0.15       112\n",
      "\n",
      "Fold Accuracy: 0.5625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.66      0.79      0.72        80\n",
      "\n",
      "    accuracy                           0.56       112\n",
      "   macro avg       0.33      0.39      0.36       112\n",
      "weighted avg       0.47      0.56      0.51       112\n",
      "\n",
      "Fold Accuracy: 0.5089285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.44        22\n",
      "           1       1.00      0.39      0.56        90\n",
      "\n",
      "    accuracy                           0.51       112\n",
      "   macro avg       0.64      0.69      0.50       112\n",
      "weighted avg       0.86      0.51      0.54       112\n",
      "\n",
      "Fold Accuracy: 0.7678571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78        56\n",
      "           1       0.81      0.70      0.75        56\n",
      "\n",
      "    accuracy                           0.77       112\n",
      "   macro avg       0.77      0.77      0.77       112\n",
      "weighted avg       0.77      0.77      0.77       112\n",
      "\n",
      "Fold Accuracy: 0.6696428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.63      0.75        89\n",
      "           1       0.37      0.83      0.51        23\n",
      "\n",
      "    accuracy                           0.67       112\n",
      "   macro avg       0.65      0.73      0.63       112\n",
      "weighted avg       0.82      0.67      0.70       112\n",
      "\n",
      "Fold Accuracy: 0.5892857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        46\n",
      "           1       0.59      1.00      0.74        66\n",
      "\n",
      "    accuracy                           0.59       112\n",
      "   macro avg       0.29      0.50      0.37       112\n",
      "weighted avg       0.35      0.59      0.44       112\n",
      "\n",
      "Fold Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.34      0.48        77\n",
      "           1       0.37      0.86      0.52        35\n",
      "\n",
      "    accuracy                           0.50       112\n",
      "   macro avg       0.60      0.60      0.50       112\n",
      "weighted avg       0.69      0.50      0.49       112\n",
      "\n",
      "Fold Accuracy: 0.8392857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74        41\n",
      "           1       0.81      0.97      0.88        71\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.87      0.79      0.81       112\n",
      "weighted avg       0.85      0.84      0.83       112\n",
      "\n",
      "Fold Accuracy: 0.8482142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88        71\n",
      "           1       0.76      0.85      0.80        41\n",
      "\n",
      "    accuracy                           0.85       112\n",
      "   macro avg       0.83      0.85      0.84       112\n",
      "weighted avg       0.85      0.85      0.85       112\n",
      "\n",
      "Fold Accuracy: 0.9017857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        80\n",
      "           1       1.00      0.66      0.79        32\n",
      "\n",
      "    accuracy                           0.90       112\n",
      "   macro avg       0.94      0.83      0.86       112\n",
      "weighted avg       0.91      0.90      0.89       112\n",
      "\n",
      "Average Accuracy across all folds: 0.6392857142857143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ta  # Technical Analysis library for financial indicators\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the data\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate technical indicators\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=20).mean()\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "\n",
    "# Drop rows with NaN values that may have been introduced by indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable for future price increase\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Select features\n",
    "features = ['Open', 'Low', 'Close', 'Volume', 'SMA_10', 'MACD', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Set up the TimeSeriesSplit cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=476, max_depth=20, random_state=42)\n",
    "\n",
    "# List to store scores and create a loop to perform cross-validation\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(\"Fold Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(\"Average Accuracy across all folds:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.20535714285714285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.26        16\n",
      "           1       1.00      0.07      0.14        96\n",
      "\n",
      "    accuracy                           0.21       112\n",
      "   macro avg       0.58      0.54      0.20       112\n",
      "weighted avg       0.88      0.21      0.15       112\n",
      "\n",
      "Fold Accuracy: 0.5625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.66      0.79      0.72        80\n",
      "\n",
      "    accuracy                           0.56       112\n",
      "   macro avg       0.33      0.39      0.36       112\n",
      "weighted avg       0.47      0.56      0.51       112\n",
      "\n",
      "Fold Accuracy: 0.44642857142857145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      1.00      0.42        22\n",
      "           1       1.00      0.31      0.47        90\n",
      "\n",
      "    accuracy                           0.45       112\n",
      "   macro avg       0.63      0.66      0.44       112\n",
      "weighted avg       0.86      0.45      0.46       112\n",
      "\n",
      "Fold Accuracy: 0.7857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        56\n",
      "           1       0.83      0.71      0.77        56\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.79      0.79      0.78       112\n",
      "weighted avg       0.79      0.79      0.78       112\n",
      "\n",
      "Fold Accuracy: 0.6607142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74        89\n",
      "           1       0.36      0.83      0.50        23\n",
      "\n",
      "    accuracy                           0.66       112\n",
      "   macro avg       0.65      0.72      0.62       112\n",
      "weighted avg       0.81      0.66      0.69       112\n",
      "\n",
      "Fold Accuracy: 0.5535714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        46\n",
      "           1       0.57      0.94      0.71        66\n",
      "\n",
      "    accuracy                           0.55       112\n",
      "   macro avg       0.29      0.47      0.36       112\n",
      "weighted avg       0.34      0.55      0.42       112\n",
      "\n",
      "Fold Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.32      0.47        77\n",
      "           1       0.37      0.89      0.53        35\n",
      "\n",
      "    accuracy                           0.50       112\n",
      "   macro avg       0.62      0.61      0.50       112\n",
      "weighted avg       0.71      0.50      0.49       112\n",
      "\n",
      "Fold Accuracy: 0.8214285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.56      0.70        41\n",
      "           1       0.79      0.97      0.87        71\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.86      0.77      0.79       112\n",
      "weighted avg       0.84      0.82      0.81       112\n",
      "\n",
      "Fold Accuracy: 0.8571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88        71\n",
      "           1       0.78      0.85      0.81        41\n",
      "\n",
      "    accuracy                           0.86       112\n",
      "   macro avg       0.84      0.86      0.85       112\n",
      "weighted avg       0.86      0.86      0.86       112\n",
      "\n",
      "Fold Accuracy: 0.9017857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        80\n",
      "           1       1.00      0.66      0.79        32\n",
      "\n",
      "    accuracy                           0.90       112\n",
      "   macro avg       0.94      0.83      0.86       112\n",
      "weighted avg       0.91      0.90      0.89       112\n",
      "\n",
      "Average Accuracy across all folds: 0.6294642857142857\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ta  # Technical Analysis library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the data\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate technical indicators\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=20).mean()\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.3).mean()\n",
    "\n",
    "# Drop rows with NaN values introduced by indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Prepare features\n",
    "features = ['Open', 'Low', 'Close', 'Volume', 'SMA_10', 'MACD', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Set up TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize AdaBoost with RandomForest as base estimator\n",
    "base_rf_classifier = RandomForestClassifier(n_estimators=476, max_depth=20, random_state=42)\n",
    "ada_boost_classifier = AdaBoostClassifier(\n",
    "    base_estimator=base_rf_classifier,\n",
    "    random_state=42,\n",
    "    n_estimators=92,\n",
    "    learning_rate=0.4232124682782118\n",
    ")\n",
    "\n",
    "# List to store scores and create a loop to perform cross-validation\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train AdaBoost with RandomForest base\n",
    "    ada_boost_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = ada_boost_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(\"Fold Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(\"Average Accuracy across all folds:\", average_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
