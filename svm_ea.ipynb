{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for NTDOY:\n",
      "              Open    High     Low   Close  Adj Close   Volume\n",
      "Date                                                          \n",
      "2019-03-01   6.926   6.950   6.866   6.934      6.934  2462500\n",
      "2019-03-04   6.810   6.828   6.704   6.742      6.742  3426500\n",
      "2019-03-05   6.796   6.826   6.750   6.810      6.810  1389000\n",
      "2019-03-06   6.910   6.958   6.910   6.930      6.930   744500\n",
      "2019-03-07   6.834   6.834   6.744   6.762      6.762  1333000\n",
      "...            ...     ...     ...     ...        ...      ...\n",
      "2024-02-23  14.000  14.030  13.920  13.960     13.960   589500\n",
      "2024-02-26  14.320  14.450  14.240  14.240     14.240  1128300\n",
      "2024-02-27  14.180  14.180  14.020  14.040     14.040   887600\n",
      "2024-02-28  13.780  13.830  13.730  13.770     13.770   880400\n",
      "2024-02-29  13.910  14.000  13.890  13.910     13.910  1060600\n",
      "\n",
      "[1259 rows x 6 columns]\n",
      "Data for TTWO:\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2019-03-01   87.709999   88.910004   86.930000   88.320000   88.320000   \n",
      "2019-03-04   88.800003   89.800003   86.320000   87.440002   87.440002   \n",
      "2019-03-05   87.720001   87.720001   86.220001   87.370003   87.370003   \n",
      "2019-03-06   87.330002   88.519997   86.959999   87.199997   87.199997   \n",
      "2019-03-07   86.949997   88.559998   86.169998   88.410004   88.410004   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2024-02-23  152.130005  153.059998  150.850006  151.009995  151.009995   \n",
      "2024-02-26  151.250000  151.460007  149.529999  149.710007  149.710007   \n",
      "2024-02-27  150.000000  150.110001  147.009995  147.940002  147.940002   \n",
      "2024-02-28  148.479996  148.500000  145.889999  147.479996  147.479996   \n",
      "2024-02-29  147.830002  148.139999  145.610001  146.929993  146.929993   \n",
      "\n",
      "             Volume  \n",
      "Date                 \n",
      "2019-03-01  2028100  \n",
      "2019-03-04  2110200  \n",
      "2019-03-05  1371600  \n",
      "2019-03-06  1342900  \n",
      "2019-03-07  1700400  \n",
      "...             ...  \n",
      "2024-02-23  1466900  \n",
      "2024-02-26  1340500  \n",
      "2024-02-27  2173100  \n",
      "2024-02-28  1589000  \n",
      "2024-02-29  2297300  \n",
      "\n",
      "[1259 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for RIOT:\n",
      "                 Open       High        Low      Close  Adj Close    Volume\n",
      "Date                                                                       \n",
      "2019-03-01   3.200000   3.480000   3.170000   3.260000   3.260000   1034500\n",
      "2019-03-04   3.170000   3.240000   2.850000   3.000000   3.000000   1139600\n",
      "2019-03-05   3.320000   3.441000   3.160000   3.390000   3.390000   1460700\n",
      "2019-03-06   3.350000   3.430000   3.220000   3.230000   3.230000    593900\n",
      "2019-03-07   3.230000   3.620000   3.110000   3.490000   3.490000   1090700\n",
      "...               ...        ...        ...        ...        ...       ...\n",
      "2024-02-23  15.140000  15.310000  14.330000  14.850000  14.850000  18732400\n",
      "2024-02-26  14.900000  17.450001  14.890000  17.370001  17.370001  39162500\n",
      "2024-02-27  18.100000  18.360001  16.219999  16.799999  16.799999  43619600\n",
      "2024-02-28  17.440001  17.590000  15.230000  15.650000  15.650000  60473200\n",
      "2024-02-29  15.680000  15.825000  13.710000  14.120000  14.120000  39477700\n",
      "\n",
      "[1259 rows x 6 columns]\n",
      "Data for EA:\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2019-03-01   96.830002   97.940002   95.309998   97.410004   95.533272   \n",
      "2019-03-04   98.309998   99.430000   95.570000   97.290001   95.415573   \n",
      "2019-03-05   96.260002   97.059998   95.150002   95.720001   93.875809   \n",
      "2019-03-06   95.320000   96.379997   94.129997   94.769997   92.944122   \n",
      "2019-03-07   95.000000   99.559998   94.470001   99.360001   97.445679   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2024-02-23  143.500000  144.199997  141.869995  142.589996  142.399979   \n",
      "2024-02-26  142.589996  143.210007  141.210007  142.580002  142.389999   \n",
      "2024-02-27  142.580002  142.580002  138.529999  139.500000  139.500000   \n",
      "2024-02-28  138.820007  140.630005  138.300003  140.080002  140.080002   \n",
      "2024-02-29  140.580002  140.639999  137.960007  139.479996  139.479996   \n",
      "\n",
      "             Volume  \n",
      "Date                 \n",
      "2019-03-01  4443600  \n",
      "2019-03-04  7187200  \n",
      "2019-03-05  6041900  \n",
      "2019-03-06  3987500  \n",
      "2019-03-07  8866800  \n",
      "...             ...  \n",
      "2024-02-23  1380000  \n",
      "2024-02-26  1984800  \n",
      "2024-02-27  2319700  \n",
      "2024-02-28  1584600  \n",
      "2024-02-29  3482300  \n",
      "\n",
      "[1259 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for TCEHY:\n",
      "                 Open       High        Low      Close  Adj Close   Volume\n",
      "Date                                                                      \n",
      "2019-03-01  42.950001  43.029999  42.430000  42.639999  39.685432  2850300\n",
      "2019-03-04  44.180000  44.240002  43.259998  43.799999  40.765049  2941500\n",
      "2019-03-05  45.709999  46.790001  45.320000  46.570000  43.343124  7615900\n",
      "2019-03-06  46.509998  46.509998  45.849998  45.930000  42.747463  2347400\n",
      "2019-03-07  45.139999  45.139999  44.259998  44.450001  41.370018  4581000\n",
      "...               ...        ...        ...        ...        ...      ...\n",
      "2024-02-23  37.060001  37.189999  36.730000  36.950001  36.950001  1665400\n",
      "2024-02-26  36.630001  36.840000  36.509998  36.529999  36.529999  2692700\n",
      "2024-02-27  36.430000  36.509998  36.349998  36.419998  36.419998  1958500\n",
      "2024-02-28  35.490002  35.490002  34.919998  34.980000  34.980000  3087100\n",
      "2024-02-29  35.250000  35.299999  34.860001  34.939999  34.939999  5149600\n",
      "\n",
      "[1259 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ticker_symbols = ['NTDOY', 'TTWO', 'RIOT', 'EA', 'TCEHY']\n",
    "\n",
    "# Get the current year\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "# Set end_date to March 1st of the current year\n",
    "end_date = datetime.date(current_year, 3, 1)\n",
    "\n",
    "# Calculate start_date as March 1st, 5 years ago from end_date\n",
    "start_date = datetime.date(current_year - 5, 3, 1)\n",
    "\n",
    "# Download stock data for each ticker\n",
    "for ticker in ticker_symbols:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    print(f\"Data for {ticker}:\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f'duplicate rows: {duplicates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for NTDOY to NTDOY_stock_data.csv\n",
      "Saved data for TTWO to TTWO_stock_data.csv\n",
      "Saved data for RIOT to RIOT_stock_data.csv\n",
      "Saved data for EA to EA_stock_data.csv\n",
      "Saved data for TCEHY to TCEHY_stock_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ticker in ticker_symbols:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    filename = f\"{ticker}_stock_data.csv\"\n",
    "    data.to_csv(filename)\n",
    "    print(f\"Saved data for {ticker} to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Open   High    Low  Close  Adj Close   Volume\n",
      "0  2019-03-01  6.926  6.950  6.866  6.934      6.934  2462500\n",
      "1  2019-03-04  6.810  6.828  6.704  6.742      6.742  3426500\n",
      "2  2019-03-05  6.796  6.826  6.750  6.810      6.810  1389000\n",
      "3  2019-03-06  6.910  6.958  6.910  6.930      6.930   744500\n",
      "4  2019-03-07  6.834  6.834  6.744  6.762      6.762  1333000\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2019-03-01  96.830002  97.940002  95.309998  97.410004  95.533249  4443600\n",
      "1  2019-03-04  98.309998  99.430000  95.570000  97.290001  95.415581  7187200\n",
      "2  2019-03-05  96.260002  97.059998  95.150002  95.720001  93.875832  6041900\n",
      "3  2019-03-06  95.320000  96.379997  94.129997  94.769997  92.944115  3987500\n",
      "4  2019-03-07  95.000000  99.559998  94.470001  99.360001  97.445694  8866800\n",
      "         Date  Open   High   Low  Close  Adj Close   Volume\n",
      "0  2019-03-01  3.20  3.480  3.17   3.26       3.26  1034500\n",
      "1  2019-03-04  3.17  3.240  2.85   3.00       3.00  1139600\n",
      "2  2019-03-05  3.32  3.441  3.16   3.39       3.39  1460700\n",
      "3  2019-03-06  3.35  3.430  3.22   3.23       3.23   593900\n",
      "4  2019-03-07  3.23  3.620  3.11   3.49       3.49  1090700\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2019-03-01  87.709999  88.910004  86.930000  88.320000  88.320000  2028100\n",
      "1  2019-03-04  88.800003  89.800003  86.320000  87.440002  87.440002  2110200\n",
      "2  2019-03-05  87.720001  87.720001  86.220001  87.370003  87.370003  1371600\n",
      "3  2019-03-06  87.330002  88.519997  86.959999  87.199997  87.199997  1342900\n",
      "4  2019-03-07  86.949997  88.559998  86.169998  88.410004  88.410004  1700400\n",
      "         Date       Open       High        Low      Close  Adj Close   Volume\n",
      "0  2019-03-01  42.950001  43.029999  42.430000  42.639999  39.685432  2850300\n",
      "1  2019-03-04  44.180000  44.240002  43.259998  43.799999  40.765053  2941500\n",
      "2  2019-03-05  45.709999  46.790001  45.320000  46.570000  43.343121  7615900\n",
      "3  2019-03-06  46.509998  46.509998  45.849998  45.930000  42.747463  2347400\n",
      "4  2019-03-07  45.139999  45.139999  44.259998  44.450001  41.370018  4581000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'NTDOY_stock_data.csv'\n",
    "ntdoy_df = pd.read_csv(file_path)\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "file_path = 'RIOT_stock_data.csv'\n",
    "riot_df = pd.read_csv(file_path)\n",
    "file_path = 'TTWO_stock_data.csv'\n",
    "ttwo_df = pd.read_csv(file_path)\n",
    "file_path = 'TCEHY_stock_data.csv'\n",
    "tchey_df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(ntdoy_df.head())\n",
    "print(ea_df.head())\n",
    "print(riot_df.head())\n",
    "print(ttwo_df.head())\n",
    "print(tchey_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1.257000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.750525</td>\n",
       "      <td>53.268600</td>\n",
       "      <td>52.209562</td>\n",
       "      <td>52.774352</td>\n",
       "      <td>50.011055</td>\n",
       "      <td>3.812732e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.564704</td>\n",
       "      <td>14.700079</td>\n",
       "      <td>14.348422</td>\n",
       "      <td>14.560980</td>\n",
       "      <td>13.236191</td>\n",
       "      <td>2.328249e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.719999</td>\n",
       "      <td>25.879999</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>25.680000</td>\n",
       "      <td>24.208784</td>\n",
       "      <td>5.726000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.150002</td>\n",
       "      <td>42.450001</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.130001</td>\n",
       "      <td>40.120689</td>\n",
       "      <td>2.350400e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.779999</td>\n",
       "      <td>48.290001</td>\n",
       "      <td>47.209999</td>\n",
       "      <td>47.830002</td>\n",
       "      <td>45.287487</td>\n",
       "      <td>3.259800e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.580002</td>\n",
       "      <td>62.549999</td>\n",
       "      <td>60.860001</td>\n",
       "      <td>61.849998</td>\n",
       "      <td>58.031876</td>\n",
       "      <td>4.612200e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.010002</td>\n",
       "      <td>99.400002</td>\n",
       "      <td>98.430000</td>\n",
       "      <td>99.099998</td>\n",
       "      <td>92.734238</td>\n",
       "      <td>2.605420e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean     52.750525    53.268600    52.209562    52.774352    50.011055   \n",
       "std      14.564704    14.700079    14.348422    14.560980    13.236191   \n",
       "min      25.719999    25.879999    24.750000    25.680000    24.208784   \n",
       "25%      42.150002    42.450001    41.740002    42.130001    40.120689   \n",
       "50%      47.779999    48.290001    47.209999    47.830002    45.287487   \n",
       "75%      61.580002    62.549999    60.860001    61.849998    58.031876   \n",
       "max      99.010002    99.400002    98.430000    99.099998    92.734238   \n",
       "\n",
       "             Volume  \n",
       "count  1.257000e+03  \n",
       "mean   3.812732e+06  \n",
       "std    2.328249e+06  \n",
       "min    5.726000e+05  \n",
       "25%    2.350400e+06  \n",
       "50%    3.259800e+06  \n",
       "75%    4.612200e+06  \n",
       "max    2.605420e+07  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tchey_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1.257000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>123.431551</td>\n",
       "      <td>124.815632</td>\n",
       "      <td>122.004845</td>\n",
       "      <td>123.432506</td>\n",
       "      <td>121.823489</td>\n",
       "      <td>2.628729e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.753103</td>\n",
       "      <td>15.775715</td>\n",
       "      <td>15.717186</td>\n",
       "      <td>15.739958</td>\n",
       "      <td>15.749835</td>\n",
       "      <td>1.465153e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>87.930000</td>\n",
       "      <td>88.949997</td>\n",
       "      <td>85.690002</td>\n",
       "      <td>86.940002</td>\n",
       "      <td>85.264969</td>\n",
       "      <td>5.839000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>113.230003</td>\n",
       "      <td>114.389999</td>\n",
       "      <td>111.830002</td>\n",
       "      <td>113.339996</td>\n",
       "      <td>112.353157</td>\n",
       "      <td>1.726300e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>126.779999</td>\n",
       "      <td>128.070007</td>\n",
       "      <td>125.449997</td>\n",
       "      <td>126.680000</td>\n",
       "      <td>125.378502</td>\n",
       "      <td>2.251400e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>136.389999</td>\n",
       "      <td>137.830002</td>\n",
       "      <td>135.110001</td>\n",
       "      <td>136.460007</td>\n",
       "      <td>135.082062</td>\n",
       "      <td>3.031500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>148.919998</td>\n",
       "      <td>150.300003</td>\n",
       "      <td>146.149994</td>\n",
       "      <td>148.970001</td>\n",
       "      <td>146.294571</td>\n",
       "      <td>1.746850e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean    123.431551   124.815632   122.004845   123.432506   121.823489   \n",
       "std      15.753103    15.775715    15.717186    15.739958    15.749835   \n",
       "min      87.930000    88.949997    85.690002    86.940002    85.264969   \n",
       "25%     113.230003   114.389999   111.830002   113.339996   112.353157   \n",
       "50%     126.779999   128.070007   125.449997   126.680000   125.378502   \n",
       "75%     136.389999   137.830002   135.110001   136.460007   135.082062   \n",
       "max     148.919998   150.300003   146.149994   148.970001   146.294571   \n",
       "\n",
       "             Volume  \n",
       "count  1.257000e+03  \n",
       "mean   2.628729e+06  \n",
       "std    1.465153e+06  \n",
       "min    5.839000e+05  \n",
       "25%    1.726300e+06  \n",
       "50%    2.251400e+06  \n",
       "75%    3.031500e+06  \n",
       "max    1.746850e+07  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ea_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1.257000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.328558</td>\n",
       "      <td>11.422229</td>\n",
       "      <td>11.240959</td>\n",
       "      <td>11.332516</td>\n",
       "      <td>11.332516</td>\n",
       "      <td>1.784015e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.997902</td>\n",
       "      <td>2.010442</td>\n",
       "      <td>1.978169</td>\n",
       "      <td>1.996392</td>\n",
       "      <td>1.996392</td>\n",
       "      <td>1.558097e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.656000</td>\n",
       "      <td>6.686000</td>\n",
       "      <td>6.612000</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>1.415000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.066000</td>\n",
       "      <td>10.180000</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>10.070000</td>\n",
       "      <td>10.070000</td>\n",
       "      <td>8.878000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.906000</td>\n",
       "      <td>10.980000</td>\n",
       "      <td>10.840000</td>\n",
       "      <td>10.906000</td>\n",
       "      <td>10.906000</td>\n",
       "      <td>1.330000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.600000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>12.482000</td>\n",
       "      <td>12.610000</td>\n",
       "      <td>12.610000</td>\n",
       "      <td>2.193500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.309999</td>\n",
       "      <td>16.510000</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>16.430000</td>\n",
       "      <td>16.430000</td>\n",
       "      <td>1.919950e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean     11.328558    11.422229    11.240959    11.332516    11.332516   \n",
       "std       1.997902     2.010442     1.978169     1.996392     1.996392   \n",
       "min       6.656000     6.686000     6.612000     6.680000     6.680000   \n",
       "25%      10.066000    10.180000     9.990000    10.070000    10.070000   \n",
       "50%      10.906000    10.980000    10.840000    10.906000    10.906000   \n",
       "75%      12.600000    12.700000    12.482000    12.610000    12.610000   \n",
       "max      16.309999    16.510000    16.309999    16.430000    16.430000   \n",
       "\n",
       "             Volume  \n",
       "count  1.257000e+03  \n",
       "mean   1.784015e+06  \n",
       "std    1.558097e+06  \n",
       "min    1.415000e+05  \n",
       "25%    8.878000e+05  \n",
       "50%    1.330000e+06  \n",
       "75%    2.193500e+06  \n",
       "max    1.919950e+07  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntdoy_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1.257000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.576244</td>\n",
       "      <td>13.191185</td>\n",
       "      <td>11.949423</td>\n",
       "      <td>12.540561</td>\n",
       "      <td>12.540561</td>\n",
       "      <td>1.328210e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.993244</td>\n",
       "      <td>13.735684</td>\n",
       "      <td>12.230499</td>\n",
       "      <td>12.934180</td>\n",
       "      <td>12.934180</td>\n",
       "      <td>1.228255e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.757000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.110000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.369000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.390000</td>\n",
       "      <td>7.770000</td>\n",
       "      <td>7.060000</td>\n",
       "      <td>7.340000</td>\n",
       "      <td>7.340000</td>\n",
       "      <td>1.062520e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.523001</td>\n",
       "      <td>18.120001</td>\n",
       "      <td>16.430000</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>1.876560e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.760002</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>67.419998</td>\n",
       "      <td>77.900002</td>\n",
       "      <td>77.900002</td>\n",
       "      <td>8.679610e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean     12.576244    13.191185    11.949423    12.540561    12.540561   \n",
       "std      12.993244    13.735684    12.230499    12.934180    12.934180   \n",
       "min       0.610000     0.700000     0.511000     0.650000     0.650000   \n",
       "25%       3.110000     3.240000     2.950000     3.100000     3.100000   \n",
       "50%       7.390000     7.770000     7.060000     7.340000     7.340000   \n",
       "75%      17.523001    18.120001    16.430000    17.350000    17.350000   \n",
       "max      72.760002    79.500000    67.419998    77.900002    77.900002   \n",
       "\n",
       "             Volume  \n",
       "count  1.257000e+03  \n",
       "mean   1.328210e+07  \n",
       "std    1.228255e+07  \n",
       "min    1.757000e+05  \n",
       "25%    3.369000e+06  \n",
       "50%    1.062520e+07  \n",
       "75%    1.876560e+07  \n",
       "max    8.679610e+07  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "riot_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1.257000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>141.534240</td>\n",
       "      <td>143.450859</td>\n",
       "      <td>139.579745</td>\n",
       "      <td>141.560366</td>\n",
       "      <td>141.560366</td>\n",
       "      <td>1.743539e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.468360</td>\n",
       "      <td>27.631334</td>\n",
       "      <td>27.138041</td>\n",
       "      <td>27.358017</td>\n",
       "      <td>27.358017</td>\n",
       "      <td>1.368869e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>86.949997</td>\n",
       "      <td>87.570000</td>\n",
       "      <td>85.830002</td>\n",
       "      <td>87.040001</td>\n",
       "      <td>87.040001</td>\n",
       "      <td>2.116000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120.940002</td>\n",
       "      <td>122.570000</td>\n",
       "      <td>118.930000</td>\n",
       "      <td>121.040001</td>\n",
       "      <td>121.040001</td>\n",
       "      <td>1.074600e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>137.869995</td>\n",
       "      <td>139.740005</td>\n",
       "      <td>136.679993</td>\n",
       "      <td>138.080002</td>\n",
       "      <td>138.080002</td>\n",
       "      <td>1.407400e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>163.919998</td>\n",
       "      <td>165.690002</td>\n",
       "      <td>161.179993</td>\n",
       "      <td>163.720001</td>\n",
       "      <td>163.720001</td>\n",
       "      <td>1.926900e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>210.479996</td>\n",
       "      <td>214.910004</td>\n",
       "      <td>209.440002</td>\n",
       "      <td>213.339996</td>\n",
       "      <td>213.339996</td>\n",
       "      <td>1.970070e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  1257.000000  1257.000000  1257.000000  1257.000000  1257.000000   \n",
       "mean    141.534240   143.450859   139.579745   141.560366   141.560366   \n",
       "std      27.468360    27.631334    27.138041    27.358017    27.358017   \n",
       "min      86.949997    87.570000    85.830002    87.040001    87.040001   \n",
       "25%     120.940002   122.570000   118.930000   121.040001   121.040001   \n",
       "50%     137.869995   139.740005   136.679993   138.080002   138.080002   \n",
       "75%     163.919998   165.690002   161.179993   163.720001   163.720001   \n",
       "max     210.479996   214.910004   209.440002   213.339996   213.339996   \n",
       "\n",
       "             Volume  \n",
       "count  1.257000e+03  \n",
       "mean   1.743539e+06  \n",
       "std    1.368869e+06  \n",
       "min    2.116000e+05  \n",
       "25%    1.074600e+06  \n",
       "50%    1.407400e+06  \n",
       "75%    1.926900e+06  \n",
       "max    1.970070e+07  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttwo_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model without ada boost and pca and technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.1).mean()\n",
    "# Define your target variable: 1 if the price goes up next week, 0 otherwise\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "svm = SVC(C=9.699920698680053,class_weight='balanced',degree=5,coef0=6.080765165859437 ,kernel='linear', gamma=0.02997773203425469, probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8531746031746031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       152\n",
      "           1       0.92      0.69      0.79       100\n",
      "\n",
      "    accuracy                           0.85       252\n",
      "   macro avg       0.87      0.83      0.84       252\n",
      "weighted avg       0.86      0.85      0.85       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "svm = SVC(C=9.699920698680053,class_weight='balanced',degree=5,coef0=6.080765165859437 ,kernel='linear', gamma=0.02997773203425469, probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation for svm without ta and adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        16\n",
      "           1       1.00      0.21      0.35        98\n",
      "\n",
      "    accuracy                           0.32       114\n",
      "   macro avg       0.59      0.61      0.32       114\n",
      "weighted avg       0.88      0.32      0.34       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.27        16\n",
      "           1       1.00      0.10      0.19        98\n",
      "\n",
      "    accuracy                           0.23       114\n",
      "   macro avg       0.58      0.55      0.23       114\n",
      "weighted avg       0.88      0.23      0.20       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.65        36\n",
      "           1       0.89      0.65      0.76        78\n",
      "\n",
      "    accuracy                           0.71       114\n",
      "   macro avg       0.71      0.74      0.70       114\n",
      "weighted avg       0.78      0.71      0.72       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63        46\n",
      "           1       1.00      0.22      0.36        68\n",
      "\n",
      "    accuracy                           0.54       114\n",
      "   macro avg       0.73      0.61      0.50       114\n",
      "weighted avg       0.78      0.54      0.47       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90        99\n",
      "           1       0.42      0.67      0.51        15\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.68      0.76      0.71       114\n",
      "weighted avg       0.88      0.83      0.85       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58        48\n",
      "           1       0.69      0.62      0.66        66\n",
      "\n",
      "    accuracy                           0.62       114\n",
      "   macro avg       0.62      0.62      0.62       114\n",
      "weighted avg       0.63      0.62      0.63       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.58      0.67        71\n",
      "           1       0.52      0.77      0.62        43\n",
      "\n",
      "    accuracy                           0.65       114\n",
      "   macro avg       0.66      0.67      0.65       114\n",
      "weighted avg       0.70      0.65      0.65       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        46\n",
      "           1       0.90      0.84      0.87        68\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.84      0.85      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88        72\n",
      "           1       0.80      0.76      0.78        42\n",
      "\n",
      "    accuracy                           0.84       114\n",
      "   macro avg       0.83      0.83      0.83       114\n",
      "weighted avg       0.84      0.84      0.84       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        80\n",
      "           1       1.00      0.59      0.74        34\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.93      0.79      0.83       114\n",
      "weighted avg       0.90      0.88      0.87       114\n",
      "\n",
      "Average Accuracy across folds: 0.6473684210526316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(C=9.699920698680053, kernel='linear', degree=5, coef0=6.080765165859437, gamma=0.02997773203425469, class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another svm with ta and removed featured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm with ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8866396761133604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       152\n",
      "           1       0.99      0.72      0.83        95\n",
      "\n",
      "    accuracy                           0.89       247\n",
      "   macro avg       0.92      0.85      0.87       247\n",
      "weighted avg       0.90      0.89      0.88       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ta  # Import the technical analysis library\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "# Assuming ea_df is your DataFrame loaded with stock data including 'Open', 'High', 'Low', 'Close', 'Volume'\n",
    "\n",
    "# Calculate Moving Average\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.2).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = [ 'High', 'Low', 'Close', 'Volume', 'SMA_10', 'MACD', 'ADX','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm = SVC(C=0.7400230211761833, kernel='rbf',degree=4,coef0=0.09111040120352687, gamma=0.2002723939261901, class_weight='balanced', probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm without ada boost and with ta with feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       152\n",
      "           1       0.96      0.76      0.85        95\n",
      "\n",
      "    accuracy                           0.89       247\n",
      "   macro avg       0.91      0.87      0.88       247\n",
      "weighted avg       0.90      0.89      0.89       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ta  # Import the technical analysis library\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "# Assuming ea_df is your DataFrame loaded with stock data including 'Open', 'High', 'Low', 'Close', 'Volume'\n",
    "\n",
    "# Calculate Moving Average\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=20).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()  \n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.2).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable: 1 if the price goes up next week, 0 otherwise\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "\n",
    "# Update features list to include the new technical indicators\n",
    "features = ['Close', 'SMA_10', 'MACD', 'ADX','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm = SVC(C=0.7400230211761833, kernel='rbf',degree=4,coef0=0.09111040120352687, gamma=0.2002723939261901, class_weight='balanced', probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV for with ta and without adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      1.00      0.34        16\n",
      "           1       1.00      0.36      0.53        96\n",
      "\n",
      "    accuracy                           0.46       112\n",
      "   macro avg       0.60      0.68      0.44       112\n",
      "weighted avg       0.89      0.46      0.51       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.25      0.29        32\n",
      "           1       0.73      0.80      0.76        80\n",
      "\n",
      "    accuracy                           0.64       112\n",
      "   macro avg       0.53      0.53      0.52       112\n",
      "weighted avg       0.61      0.64      0.63       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62        22\n",
      "           1       1.00      0.70      0.82        90\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.72      0.85      0.72       112\n",
      "weighted avg       0.89      0.76      0.78       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.95      0.80        56\n",
      "           1       0.91      0.57      0.70        56\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.80      0.76      0.75       112\n",
      "weighted avg       0.80      0.76      0.75       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86        89\n",
      "           1       0.50      0.83      0.62        23\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.72      0.81      0.74       112\n",
      "weighted avg       0.85      0.79      0.81       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.20      0.29        46\n",
      "           1       0.61      0.88      0.72        66\n",
      "\n",
      "    accuracy                           0.60       112\n",
      "   macro avg       0.57      0.54      0.50       112\n",
      "weighted avg       0.58      0.60      0.54       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.43        77\n",
      "           1       0.38      1.00      0.56        35\n",
      "\n",
      "    accuracy                           0.50       112\n",
      "   macro avg       0.69      0.64      0.49       112\n",
      "weighted avg       0.81      0.50      0.47       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.80        41\n",
      "           1       0.93      0.80      0.86        71\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.83      0.85      0.83       112\n",
      "weighted avg       0.86      0.84      0.84       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93        71\n",
      "           1       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.90       112\n",
      "   macro avg       0.91      0.88      0.89       112\n",
      "weighted avg       0.91      0.90      0.90       112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        80\n",
      "           1       1.00      0.41      0.58        32\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.90      0.70      0.74       112\n",
      "weighted avg       0.86      0.83      0.80       112\n",
      "\n",
      "Average Accuracy across folds: 0.7080357142857144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(C=0.7400230211761833, kernel='rbf', degree=4, coef0=0.09111040120352687, gamma=0.2002723939261901, class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8906882591093117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       152\n",
      "           1       1.00      0.72      0.83        95\n",
      "\n",
      "    accuracy                           0.89       247\n",
      "   macro avg       0.92      0.86      0.88       247\n",
      "weighted avg       0.91      0.89      0.89       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize the SVM model with probability=True for AdaBoost compatibility\n",
    "svm_base = SVC(C=8, kernel='rbf', gamma=0.01, class_weight=None, probability=True, random_state=42)\n",
    "\n",
    "# Initialize and train the AdaBoost model with SVM as the base estimator\n",
    "ada_boost_model = AdaBoostClassifier(base_estimator=svm_base, n_estimators=50, random_state=42)\n",
    "ada_boost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the AdaBoost model\n",
    "y_pred = ada_boost_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(C=0.7400230211761833, kernel='rbf', degree=4, coef0=0.09111040120352687, gamma=0.2002723939261901, class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm without ta and with adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8690476190476191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       152\n",
      "           1       1.00      0.67      0.80       100\n",
      "\n",
      "    accuracy                           0.87       252\n",
      "   macro avg       0.91      0.83      0.85       252\n",
      "weighted avg       0.89      0.87      0.86       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.1).mean()\n",
    "# Define your target variable: 1 if the price goes up next week, 0 otherwise\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Initialize the SVM model with probability=True for AdaBoost compatibility\n",
    "svm_base = SVC(C=8, kernel='rbf', gamma=0.01, class_weight=None, probability=True, random_state=42)\n",
    "\n",
    "# Initialize and train the AdaBoost model with SVM as the base estimator\n",
    "ada_boost_model = AdaBoostClassifier(base_estimator=svm_base, n_estimators=50, random_state=42)\n",
    "ada_boost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the AdaBoost model\n",
    "y_pred = ada_boost_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best hyper parameter search for svm without ta and adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:47<00:00,  1.07s/trial, best loss: -0.7213495225447417]\n",
      "Best parameters: {'C': 9.699920698680053, 'class_weight': 'balanced', 'coef0': 6.080765165859437, 'degree': 5, 'gamma': 0.02997773203425469, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming ea_df is previously defined and loaded with data\n",
    "# ea_df = pd.read_csv('path_to_your_data.csv')\n",
    "\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.1).mean()\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "y = ea_df['Target']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "space = {\n",
    "    'C': hp.uniform('C', 0.01, 100),\n",
    "    'gamma': hp.uniform('gamma', 0.01, 5),\n",
    "    'kernel': hp.choice('kernel', ['rbf']),\n",
    "    'degree': hp.choice('degree', [2, 3, 4, 5]),\n",
    "    'coef0': hp.uniform('coef0', 0.0, 10.0),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced'])\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    clf = SVC(**params, probability=True, random_state=42)\n",
    "    score = cross_val_score(clf, X_scaled, y, scoring='accuracy').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "best['kernel'] = ['linear', 'rbf', 'poly', 'sigmoid'][best['kernel']]\n",
    "best['degree'] = [2, 3, 4, 5][best['degree']]\n",
    "best['class_weight'] = [None, 'balanced'][best['class_weight']]\n",
    "\n",
    "print(\"Best parameters:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyper parameters for svm with ta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:39<00:00,  1.01trial/s, best loss: -0.7436734693877551]\n",
      "Best parameters: {'C': 0.7400230211761833, 'class_weight': 'balanced', 'coef0': 0.09111040120352687, 'degree': 4, 'gamma': 0.2002723939261901, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import ta  # Import the technical analysis library\n",
    "\n",
    "# Assuming ea_df is previously defined and loaded with data\n",
    "# ea_df = pd.read_csv('path_to_your_data.csv')\n",
    "\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=10).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "\n",
    "# Calculate ADX\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.2).mean()\n",
    "# Drop any rows with NaN values that were introduced by the indicator calculations\n",
    "ea_df.dropna(inplace=True)\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "y = ea_df['Target']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "space = {\n",
    "    'C': hp.uniform('C', 0.01, 100),\n",
    "    'gamma': hp.uniform('gamma', 0.01, 5),\n",
    "    'kernel': hp.choice('kernel', ['rbf']),\n",
    "    'degree': hp.choice('degree', [2, 3, 4, 5]),\n",
    "    'coef0': hp.uniform('coef0', 0.0, 10.0),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced'])\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    clf = SVC(**params, probability=True, random_state=42)\n",
    "    score = cross_val_score(clf, X_scaled, y, scoring='accuracy').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "best['kernel'] = ['linear', 'rbf', 'poly', 'sigmoid'][best['kernel']]\n",
    "best['degree'] = [2, 3, 4, 5][best['degree']]\n",
    "best['class_weight'] = [None, 'balanced'][best['class_weight']]\n",
    "\n",
    "print(\"Best parameters:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyper parameters for svm with ta and adaboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [4:47:54<00:00, 172.74s/trial, best loss: -0.7715842138178466] \n",
      "Best parameters: {'C': 98.09738852903301, 'algorithm': 0, 'class_weight': None, 'coef0': 4.561076344128647, 'degree': 2, 'gamma': 0.06514441289951156, 'kernel': 'rbf', 'learning_rate': 0.671993194805663, 'n_estimators_ab': 171.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Assuming X_scaled and y are defined, for example, by:\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=0, random_state=42)\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "space = {\n",
    "    'C': hp.uniform('C', 0.01, 100),\n",
    "    'gamma': hp.uniform('gamma', 0.01, 5),\n",
    "    'kernel': hp.choice('kernel', ['rbf']),  # If you only intend to test 'rbf', this could be fixed instead of using hp.choice\n",
    "    'degree': hp.choice('degree', [2, 3, 4, 5]),\n",
    "    'coef0': hp.uniform('coef0', 0.0, 10.0),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'n_estimators_ab': scope.int(hp.quniform('n_estimators_ab', 50, 200, 1)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 1.0),\n",
    "    'algorithm': hp.choice('algorithm', ['SAMME', 'SAMME.R'])\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    # Adjust SVC instantiation to pass **params directly, ensuring all SVC-related hyperparams are used\n",
    "    svc = SVC(probability=True, **{k: v for k, v in params.items() if k in ['C', 'gamma', 'kernel', 'degree', 'coef0', 'class_weight']})\n",
    "    \n",
    "    # Instantiate AdaBoost with the SVC base estimator\n",
    "    clf = AdaBoostClassifier(\n",
    "        base_estimator=svc,\n",
    "        n_estimators=params['n_estimators_ab'],  # Make sure n_estimators is cast to int if needed\n",
    "        learning_rate=params['learning_rate'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    score = cross_val_score(clf, X_scaled, y, scoring='accuracy').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "# Since 'kernel' and 'class_weight' are the only hyperparameters chosen with hp.choice, map them back to their string representations\n",
    "best['kernel'] = ['rbf'][best['kernel']]  # Adjust accordingly if more options are added later\n",
    "best['class_weight'] = [None, 'balanced'][best['class_weight']]\n",
    "\n",
    "print(\"Best parameters:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> split cross validation with best hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without ta and adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:59<00:00,  1.67trial/s, best loss: -0.7119617224880382]\n",
      "Best parameters: {'C': 30.615622222954407, 'class_weight': 'balanced', 'coef0': 6.588366669688766, 'degree': 2, 'gamma': 0.34292238995846713, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming ea_df is previously defined and loaded with data\n",
    "# ea_df = pd.read_csv('path_to_your_data.csv')\n",
    "file_path = 'EA_stock_data.csv'\n",
    "\n",
    "ea_df = pd.read_csv(file_path)\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.1).mean()\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "y = ea_df['Target']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define TimeSeriesSplit cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "space = {\n",
    "    'C': hp.uniform('C', 0.01, 100),\n",
    "    'gamma': hp.uniform('gamma', 0.01, 5),\n",
    "    'kernel': hp.choice('kernel', ['rbf']),\n",
    "    'degree': hp.choice('degree', [2, 3, 4, 5]),\n",
    "    'coef0': hp.uniform('coef0', 0.0, 10.0),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced'])\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    clf = SVC(**params, probability=True, random_state=42)\n",
    "    # Here we use TimeSeriesSplit in cross_val_score\n",
    "    score = cross_val_score(clf, X_scaled, y, cv=tscv, scoring='accuracy').mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "\n",
    "# Convert indexes back to parameter values\n",
    "best['kernel'] = 'rbf'  # since you had hp.choice with only one option 'rbf'\n",
    "best['degree'] = [2, 3, 4, 5][best['degree']]\n",
    "best['class_weight'] = [None, 'balanced'][best['class_weight']]\n",
    "\n",
    "print(\"Best parameters:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8531746031746031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       152\n",
      "           1       0.83      0.79      0.81       100\n",
      "\n",
      "    accuracy                           0.85       252\n",
      "   macro avg       0.85      0.84      0.85       252\n",
      "weighted avg       0.85      0.85      0.85       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Target'] = ea_df['Target'].astype('category')\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.1).mean()\n",
    "# Define your target variable: 1 if the price goes up next week, 0 otherwise\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume','Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "svm = SVC(C=30.61562222295440,class_weight='balanced',degree=2,coef0= 6.588366669688766 ,kernel='rbf', gamma= 0.34292238995846713, probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.85      0.67        48\n",
      "           1       0.95      0.79      0.86       161\n",
      "\n",
      "    accuracy                           0.80       209\n",
      "   macro avg       0.75      0.82      0.76       209\n",
      "weighted avg       0.86      0.80      0.82       209\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.84      0.72       103\n",
      "           1       0.77      0.51      0.61       106\n",
      "\n",
      "    accuracy                           0.67       209\n",
      "   macro avg       0.70      0.68      0.67       209\n",
      "weighted avg       0.70      0.67      0.67       209\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.50      0.63       121\n",
      "           1       0.56      0.88      0.68        88\n",
      "\n",
      "    accuracy                           0.66       209\n",
      "   macro avg       0.70      0.69      0.65       209\n",
      "weighted avg       0.72      0.66      0.65       209\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.20      0.32       106\n",
      "           1       0.54      0.97      0.69       103\n",
      "\n",
      "    accuracy                           0.58       209\n",
      "   macro avg       0.71      0.58      0.51       209\n",
      "weighted avg       0.71      0.58      0.51       209\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       136\n",
      "           1       0.80      0.75      0.77        73\n",
      "\n",
      "    accuracy                           0.85       209\n",
      "   macro avg       0.83      0.83      0.83       209\n",
      "weighted avg       0.85      0.85      0.85       209\n",
      "\n",
      "Average Accuracy across folds: 0.7119617224880382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(C=30.61562222295440,class_weight='balanced',degree=2,coef0= 6.588366669688766 ,kernel='rbf', gamma= 0.34292238995846713, probability=True, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform the time series cross-validation\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Print the classification report for each fold\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy across folds: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.32456140350877194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        16\n",
      "           1       1.00      0.21      0.35        98\n",
      "\n",
      "    accuracy                           0.32       114\n",
      "   macro avg       0.59      0.61      0.32       114\n",
      "weighted avg       0.88      0.32      0.34       114\n",
      "\n",
      "Fold Accuracy: 0.22807017543859648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.27        16\n",
      "           1       1.00      0.10      0.19        98\n",
      "\n",
      "    accuracy                           0.23       114\n",
      "   macro avg       0.58      0.55      0.23       114\n",
      "weighted avg       0.88      0.23      0.20       114\n",
      "\n",
      "Fold Accuracy: 0.7105263157894737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.65        36\n",
      "           1       0.89      0.65      0.76        78\n",
      "\n",
      "    accuracy                           0.71       114\n",
      "   macro avg       0.71      0.74      0.70       114\n",
      "weighted avg       0.78      0.71      0.72       114\n",
      "\n",
      "Fold Accuracy: 0.5350877192982456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63        46\n",
      "           1       1.00      0.22      0.36        68\n",
      "\n",
      "    accuracy                           0.54       114\n",
      "   macro avg       0.73      0.61      0.50       114\n",
      "weighted avg       0.78      0.54      0.47       114\n",
      "\n",
      "Fold Accuracy: 0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90        99\n",
      "           1       0.42      0.67      0.51        15\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.68      0.76      0.71       114\n",
      "weighted avg       0.88      0.83      0.85       114\n",
      "\n",
      "Fold Accuracy: 0.6228070175438597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58        48\n",
      "           1       0.69      0.62      0.66        66\n",
      "\n",
      "    accuracy                           0.62       114\n",
      "   macro avg       0.62      0.62      0.62       114\n",
      "weighted avg       0.63      0.62      0.63       114\n",
      "\n",
      "Fold Accuracy: 0.6491228070175439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.58      0.67        71\n",
      "           1       0.52      0.77      0.62        43\n",
      "\n",
      "    accuracy                           0.65       114\n",
      "   macro avg       0.66      0.67      0.65       114\n",
      "weighted avg       0.70      0.65      0.65       114\n",
      "\n",
      "Fold Accuracy: 0.8508771929824561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        46\n",
      "           1       0.90      0.84      0.87        68\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.84      0.85      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "Fold Accuracy: 0.8421052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88        72\n",
      "           1       0.80      0.76      0.78        42\n",
      "\n",
      "    accuracy                           0.84       114\n",
      "   macro avg       0.83      0.83      0.83       114\n",
      "weighted avg       0.84      0.84      0.84       114\n",
      "\n",
      "Fold Accuracy: 0.8771929824561403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        80\n",
      "           1       1.00      0.59      0.74        34\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.93      0.79      0.83       114\n",
      "weighted avg       0.90      0.88      0.87       114\n",
      "\n",
      "Average Accuracy across all folds: 0.6473684210526316\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the data\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the data\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.1).mean()\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "y = ea_df['Target']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Set up the TimeSeriesSplit cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(C=9.699920698680053, class_weight='balanced', degree=5, coef0=6.080765165859437,\n",
    "          kernel='linear', gamma=0.02997773203425469, probability=True, random_state=42)\n",
    "\n",
    "# List to store scores and create a loop to perform cross-validation\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the SVM model\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(\"Fold Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(\"Average Accuracy across all folds:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.44642857142857145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      1.00      0.34        16\n",
      "           1       1.00      0.35      0.52        96\n",
      "\n",
      "    accuracy                           0.45       112\n",
      "   macro avg       0.60      0.68      0.43       112\n",
      "weighted avg       0.89      0.45      0.50       112\n",
      "\n",
      "Fold accuracy: 0.5803571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.67      0.81      0.73        80\n",
      "\n",
      "    accuracy                           0.58       112\n",
      "   macro avg       0.34      0.41      0.37       112\n",
      "weighted avg       0.48      0.58      0.52       112\n",
      "\n",
      "Fold accuracy: 0.7946428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66        22\n",
      "           1       1.00      0.74      0.85        90\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.74      0.87      0.76       112\n",
      "weighted avg       0.90      0.79      0.81       112\n",
      "\n",
      "Fold accuracy: 0.7410714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.78        56\n",
      "           1       0.89      0.55      0.68        56\n",
      "\n",
      "    accuracy                           0.74       112\n",
      "   macro avg       0.78      0.74      0.73       112\n",
      "weighted avg       0.78      0.74      0.73       112\n",
      "\n",
      "Fold accuracy: 0.8660714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        89\n",
      "           1       0.63      0.83      0.72        23\n",
      "\n",
      "    accuracy                           0.87       112\n",
      "   macro avg       0.79      0.85      0.81       112\n",
      "weighted avg       0.89      0.87      0.87       112\n",
      "\n",
      "Fold accuracy: 0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.15      0.23        46\n",
      "           1       0.59      0.86      0.70        66\n",
      "\n",
      "    accuracy                           0.57       112\n",
      "   macro avg       0.52      0.51      0.46       112\n",
      "weighted avg       0.53      0.57      0.51       112\n",
      "\n",
      "Fold accuracy: 0.48214285714285715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40        77\n",
      "           1       0.38      1.00      0.55        35\n",
      "\n",
      "    accuracy                           0.48       112\n",
      "   macro avg       0.69      0.62      0.47       112\n",
      "weighted avg       0.81      0.48      0.44       112\n",
      "\n",
      "Fold accuracy: 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        41\n",
      "           1       0.97      0.93      0.95        71\n",
      "\n",
      "    accuracy                           0.94       112\n",
      "   macro avg       0.93      0.94      0.93       112\n",
      "weighted avg       0.94      0.94      0.94       112\n",
      "\n",
      "Fold accuracy: 0.9107142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        71\n",
      "           1       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.91       112\n",
      "   macro avg       0.92      0.89      0.90       112\n",
      "weighted avg       0.91      0.91      0.91       112\n",
      "\n",
      "Fold accuracy: 0.8392857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        80\n",
      "           1       1.00      0.44      0.61        32\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.91      0.72      0.75       112\n",
      "weighted avg       0.87      0.84      0.82       112\n",
      "\n",
      "Average Accuracy across all folds: 0.7169642857142857\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ta  # Import the technical analysis library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your data\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate technical indicators\n",
    "ea_df['SMA_10'] = ea_df['Close'].rolling(window=20).mean()\n",
    "ea_df['MACD'] = ta.trend.MACD(ea_df['Close']).macd()\n",
    "ea_df['ADX'] = ta.trend.ADXIndicator(ea_df['High'], ea_df['Low'], ea_df['Close'], window=14).adx()\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.2).mean()\n",
    "\n",
    "# Ensure all technical indicators are calculated before dropping NaNs\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define the target variable for future price increase over the next 80 days\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "\n",
    "# Feature selection\n",
    "features = ['Close', 'SMA_10', 'MACD', 'ADX', 'Smoothed_Close']\n",
    "X = ea_df[features].values\n",
    "y = ea_df['Target'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(C=0.7400230211761833, kernel='rbf', degree=4, coef0=0.09111040120352687, gamma=0.2002723939261901, class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "# Rolling window cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the SVM model\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(\"Fold accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Print the average accuracy\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(\"Average Accuracy across all folds:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.4298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      1.00      0.33        16\n",
      "           1       1.00      0.34      0.50        98\n",
      "\n",
      "    accuracy                           0.43       114\n",
      "   macro avg       0.60      0.67      0.42       114\n",
      "weighted avg       0.89      0.43      0.48       114\n",
      "\n",
      "Fold Accuracy: 0.8596491228070176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.86      1.00      0.92        98\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.43      0.50      0.46       114\n",
      "weighted avg       0.74      0.86      0.79       114\n",
      "\n",
      "Fold Accuracy: 0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.68      1.00      0.81        78\n",
      "\n",
      "    accuracy                           0.68       114\n",
      "   macro avg       0.34      0.50      0.41       114\n",
      "weighted avg       0.47      0.68      0.56       114\n",
      "\n",
      "Fold Accuracy: 0.5964912280701754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        46\n",
      "           1       0.60      1.00      0.75        68\n",
      "\n",
      "    accuracy                           0.60       114\n",
      "   macro avg       0.30      0.50      0.37       114\n",
      "weighted avg       0.36      0.60      0.45       114\n",
      "\n",
      "Fold Accuracy: 0.13157894736842105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        99\n",
      "           1       0.13      1.00      0.23        15\n",
      "\n",
      "    accuracy                           0.13       114\n",
      "   macro avg       0.07      0.50      0.12       114\n",
      "weighted avg       0.02      0.13      0.03       114\n",
      "\n",
      "Fold Accuracy: 0.7105263157894737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65        48\n",
      "           1       0.74      0.77      0.76        66\n",
      "\n",
      "    accuracy                           0.71       114\n",
      "   macro avg       0.70      0.70      0.70       114\n",
      "weighted avg       0.71      0.71      0.71       114\n",
      "\n",
      "Fold Accuracy: 0.631578947368421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.45      0.60        71\n",
      "           1       0.51      0.93      0.66        43\n",
      "\n",
      "    accuracy                           0.63       114\n",
      "   macro avg       0.71      0.69      0.63       114\n",
      "weighted avg       0.76      0.63      0.62       114\n",
      "\n",
      "Fold Accuracy: 0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88        46\n",
      "           1       0.95      0.87      0.91        68\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "Fold Accuracy: 0.8771929824561403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91        72\n",
      "           1       0.97      0.69      0.81        42\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.91      0.84      0.86       114\n",
      "weighted avg       0.89      0.88      0.87       114\n",
      "\n",
      "Fold Accuracy: 0.8421052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        80\n",
      "           1       1.00      0.47      0.64        34\n",
      "\n",
      "    accuracy                           0.84       114\n",
      "   macro avg       0.91      0.74      0.77       114\n",
      "weighted avg       0.87      0.84      0.82       114\n",
      "\n",
      "Average Accuracy across all folds: 0.6657894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "file_path = 'EA_stock_data.csv'\n",
    "ea_df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the data\n",
    "ea_df.dropna(inplace=True)\n",
    "ea_df['Smoothed_Close'] = ea_df['Close'].ewm(alpha=0.1).mean()\n",
    "ea_df['Target'] = (ea_df['Adj Close'].shift(-80) > ea_df['Adj Close']).astype(int)\n",
    "ea_df.dropna(inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Smoothed_Close']\n",
    "X = ea_df[features]\n",
    "y = ea_df['Target']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Set up the TimeSeriesSplit cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Initialize the SVM model with probability=True for AdaBoost compatibility\n",
    "svm_base = SVC(C=8, kernel='rbf', gamma=0.01, class_weight=None, probability=True, random_state=42)\n",
    "\n",
    "# List to store scores and create a loop to perform cross-validation\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train the AdaBoost model with SVM as the base estimator\n",
    "    ada_boost_model = AdaBoostClassifier(base_estimator=svm_base, n_estimators=50, random_state=42)\n",
    "    ada_boost_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and evaluate the AdaBoost model\n",
    "    y_pred = ada_boost_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(\"Fold Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(\"Average Accuracy across all folds:\", average_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
